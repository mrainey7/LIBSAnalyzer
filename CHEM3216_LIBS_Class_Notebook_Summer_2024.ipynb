{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D7IugKKSnZK"
      },
      "source": [
        "# **Laser-Induced Breakdown Spectroscopy Data Analysis Notebook**\n",
        "\n",
        "### Please save yourself a copy of this notebook, rather than editing the class copy. Go to the top left corner under \"File\", and click \"Save a Copy in Drive\". A new copy of the notebook will open in another tab--rename the notebook and you're ready to start!\n",
        "\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "This code is meant to help merge LIBS Excel files into an easier to read format and can help in the automatic determination of the elements present in a sample. The code is designed to be excutable without requiring a background in Python. It is expected that you have completed the corresponding LIBS prelab and have read the LIBS protocol before using this tool. If you have any questions, please let Markace Rainey know at mrainey7@gatech.edu."
      ],
      "id": "5D7IugKKSnZK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqI8wc26U0UR"
      },
      "source": [
        "First, let's import some common Python packages that are already included in the Google Colab environment. Packages are just collections of prewritten code that we can reuse in many different contexts. For example, we will use the plotly package to produce interactive plots!"
      ],
      "id": "jqI8wc26U0UR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bee79444"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# IMPORTING COMMON PACKAGES\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics\n",
        "import plotly.express as px\n",
        "import time\n",
        "import plotly.graph_objects as go"
      ],
      "id": "bee79444"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68_oWX84TnA1"
      },
      "source": [
        "Now, let's check whether the Python package Astroquery is installed. If it is, we'll just import it. It not, we'll install it, then import it.\n",
        "Astroquery is a package that allows us to call information directly from the NIST Atomic Lines Database."
      ],
      "id": "68_oWX84TnA1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab065139"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# IMPORTING ASTROQUERY\n",
        "\n",
        "import pip\n",
        "\n",
        "def import_or_install(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(\"Astroquery imported successfully!\")\n",
        "    except ImportError:\n",
        "        print(\"Astroquery not installed. Attempting installation.\")\n",
        "        pip.main(['install', package])\n",
        "        print(\"Astroquery imported successfully!\")\n",
        "\n",
        "import_or_install('astroquery')\n",
        "\n",
        "from astroquery.nist import Nist\n",
        "import astropy.units as u"
      ],
      "id": "ab065139"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_8Le9_0X__0"
      },
      "source": [
        "The following coding block shows how Astroquery works.\n",
        "First, we have to specify lower and upper wavelength bounds. The example below searches between 0 nm and 10000 nm; note that the 'u.nm' portion refers to us importing the definition of a nanometer from the units module above.\n",
        "Next, we have to specify which atom type we are interested in. The example below retrieves the lines for 'Cu I', which represents neutral copper. The remaining query terms are not important for our analysis."
      ],
      "id": "Y_8Le9_0X__0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bee0f2f2"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# PRACTICING ASTROQUERY SEARCHES, PART 1\n",
        "\n",
        "\n",
        "table = Nist.query(minwav=0*u.nm, maxwav=10000*u.nm, linename='Cu I')\n",
        "print(table)\n"
      ],
      "id": "bee0f2f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrhLBSpEaMKC"
      },
      "source": [
        "Notice that the table is cutting off part of the information and that it includes some columns we might not be interested in. The section below will clean up the table for us, including the removal of lines without relative intensity data. By default, the table is ranked by intensity value, but we can make the table interactive by clicking the magic wand button that says, \"Convert this dataframe into an interactive table\"."
      ],
      "id": "OrhLBSpEaMKC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d057d8ea"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# CREATING STREAMLINED TABLE\n",
        "\n",
        "import astropy.units as u\n",
        "\n",
        "min_value = 200  # replace with your actual minimum value\n",
        "max_value = 850  # replace with your actual maximum value\n",
        "\n",
        "# Assuming 'table' is a DataFrame you defined earlier from \"Cu I\"\n",
        "datatable_version = table.to_pandas()\n",
        "\n",
        "# Create a clean copy of the data to avoid SettingWithCopyWarning\n",
        "datatable_version_clean = datatable_version.dropna(subset=[\"Rel.\"]).copy()\n",
        "\n",
        "# Extracting digits and handling missing values\n",
        "datatable_version_clean['Intensity'] = [''.join(filter(str.isdigit, str(i))) for i in datatable_version_clean[\"Rel.\"]]\n",
        "datatable_version_clean['Intensity'].replace('', np.nan, inplace=True)\n",
        "datatable_version_clean.dropna(subset=[\"Intensity\"], inplace=True)\n",
        "\n",
        "# Convert 'Intensity' to integers\n",
        "datatable_version_clean['Intensity'] = datatable_version_clean['Intensity'].astype(int)\n",
        "\n",
        "# Sorting and dropping unnecessary columns\n",
        "datatable_version_clean.sort_values(by=['Intensity'], ascending=False, inplace=True)\n",
        "datatable_version_clean.drop(columns=[\"Aki\", \"Ei           Ek\", \"Ritz\", \"fik\", \"Transition\", \"Acc.\", \"Type\", \"TP\"], inplace=True)\n",
        "\n",
        "# Convert 'Observed' column to numeric type (float)\n",
        "datatable_version_clean['Observed'] = pd.to_numeric(datatable_version_clean['Observed'], errors='coerce')\n",
        "\n",
        "# Now apply the filter with numerical comparison\n",
        "filtered_table = datatable_version_clean[(datatable_version_clean['Observed'] > min_value) & (datatable_version_clean['Observed'] < max_value)]\n",
        "\n",
        "# Display the filtered table\n",
        "display(filtered_table)\n",
        "\n"
      ],
      "id": "d057d8ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnPYQg02cXw0"
      },
      "source": [
        "Now that we have imported the required packages and are familiar with Astroquery search process, let's switch to looking at our data. First, we need to import our data into Google Colab from our computer. The next coding block will import an Excel file of our choosing; it will then appear in the Files tab that can be viewed by clicking the folder icon on the left-hand panel. Note: There is an occassional error with loading large files, try to rerun the cell a couple of times and it typically works if you are using Google Chrome. If it continues to fail, work with a partner and email Markace (mrainey7@gatech.edu)."
      ],
      "id": "jnPYQg02cXw0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPhtTMD6Peck"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# UPLOADING EXCEL DATA\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for initial_file_name in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=initial_file_name, length=len(uploaded[initial_file_name])))"
      ],
      "id": "mPhtTMD6Peck"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4dTjr11HBX4"
      },
      "source": [
        "Our LIBS instrument is designed to measure emitted light with a high spectral resolution within the timescale of a laser pulse. To accomplish this goal, we split the emission light into 8 separate spectrometers that each measure a different range of the electromagnetic spectrum in parallel. Unfortunately, the Avasoft software used in our lab exports the data for each of these spectrometers as separate sheets in an Excel workbook. To save you time, the code block below will merge the values on each sheet, then save a new copy of the Excel workbook under the files tab on the left-hand panel. The new Excel workbook will have the same name as your input file, but with \"_merged\" added to the end. You can view this new document by visting the files tab on the lefthand panel (folder icon), and you can download this merged version for future use."
      ],
      "id": "t4dTjr11HBX4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e079d428"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# CREATING MERGED EXCEL FILE\n",
        "\n",
        "xl = pd.ExcelFile(initial_file_name)\n",
        "print(\"The name of the input file was:\", initial_file_name)\n",
        "if len(xl.sheet_names) > 1:\n",
        "  print(\"There are\", len(xl.sheet_names), \"sheets in the uploaded Excel file. We will merge the sheets for you.\")\n",
        "  full_wavelength = []\n",
        "  full_intensity = []\n",
        "  for i in xl.sheet_names:\n",
        "      full_data = xl.parse(i)\n",
        "      full_data.reset_index()\n",
        "      wavelengths = full_data.iloc[:, 0]\n",
        "      intensities = full_data.iloc[:, 1]\n",
        "      list_wave = list(wavelengths[range(7,len(wavelengths))])\n",
        "      list_intensity = list(intensities[range(7,len(intensities))])\n",
        "      full_wavelength.extend(list_wave)\n",
        "      full_intensity.extend(list_intensity)\n",
        "  new_book = pd.DataFrame({'Wavelength (nm)':full_wavelength,'Intensity (au)':full_intensity})\n",
        "\n",
        "elif len(xl.sheet_names) == 1:\n",
        "  new_book = pd.read_excel(xl)\n",
        "  print(\"The uploaded file appears to already be a single sheet. Only the column titles have been updated.\")\n",
        "\n",
        "final_file_name = initial_file_name[:len(initial_file_name)-5] + '_merged.xlsx'\n",
        "print(\"The name of the output file is:\", final_file_name)\n",
        "\n",
        "new_book.to_excel(final_file_name)"
      ],
      "id": "e079d428"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oEG4Tg3K4wS"
      },
      "source": [
        "Now, let's take a look at the full spectrum for our data. The plot you generate below is fully interactive. There are a list of tools and plot saving options in the toolbar in the top right of the graph. You can save an image of this graph by clicking the camera icon on the plotly toolbar. Pro tip: If you accidently zoom in, double clicking on the graph will reset the axes."
      ],
      "id": "6oEG4Tg3K4wS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a58a410"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# PLOTTING LIBS SPECTRUM\n",
        "\n",
        "df = new_book\n",
        "fig = px.line(x=df[\"Wavelength (nm)\"], y=df[\"Intensity (au)\"])\n",
        "fig.update_layout(xaxis=dict(title='Wavelength (nm)', showgrid=False),\n",
        "              yaxis=dict(title='Intensity (Counts)'))\n",
        "fig.update_layout(template = 'none', height = 500, width = 1500)\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "config = {'displayModeBar': True}\n",
        "fig.show(config=config)"
      ],
      "id": "0a58a410"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah-i-nBAMHVd"
      },
      "source": [
        "### Click the coding block following this text, then come back and read this info. The code takes a couple of minutes!\n",
        "---\n",
        "\n",
        "When your spectrum was collected, you presumably adjusted the experimental parameters to alleviate baseline noise and improve the signal. However, baseline noise is ever-present, and the baseline may vary dramatically between different spectrometers. This variation can make the automatic assignment of peaks difficult since a genuine peak in one location might be lower than the baseline in another. To facilitate our analysis, we must apply baseline correction.\n",
        "\n",
        "**Approach**\n",
        "\n",
        "In our approach, we will use median baseline correction. We'll create boxes centered on each data point, including the 40 closest neighbors on both the left and the right. We will find the median of those 81 points and subtract it from the center point. We'll repeat this process for each point, and any resulting intensity values less than zero will be set to zero.\n",
        "\n",
        "**Reasoning**\n",
        "\n",
        "Peaks in a spectrum are relatively rare. If you select 81 neighboring points, most of those points will likely represent the baseline. Therefore, the median of those 81 points is a good estimation of the baseline at that location. By removing the median of each box, we should be effectively eliminating the baseline fluctuations!\n",
        "\n",
        "**Complication**\n",
        "\n",
        "Sometimes, merely subtracting the median of the box may not be enough to remove the baseline variations. In those instances, we can subtract higher multiples of the median until the baseline is satisfactorily corrected. The graph below includes a slider that illustrates what happens when you subtract different multiples of the median. Notice that increasing the multiple will lead to more correction but may result in overcorrection. Undercorrection might cause us to mistakenly match peaks to elements not present in our sample, while overcorrection could lead us to overlook elements present in low abundance. Play with the slider below to explore the effects of different correction levels (note: the median factor is a multiple of the median we are subtracting, so adjusting it changes the degree of correction)."
      ],
      "id": "Ah-i-nBAMHVd"
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL\n",
        "# EXAMINE BASELINE CORRECTION\n",
        "\n",
        "# Helper function to apply baseline correction\n",
        "def correct_intensity(df, step, window_size=40):\n",
        "    corrected_intensity = [\n",
        "        max(intensity - statistics.median(df[\"Intensity (au)\"][max(i-window_size, 0):min(i+window_size, len(df))]) * step, 0)\n",
        "        for i, intensity in enumerate(df[\"Intensity (au)\"])]\n",
        "    return corrected_intensity\n",
        "\n",
        "# Create figure\n",
        "fig = go.Figure()\n",
        "step_width = 0.1\n",
        "window_size = 40\n",
        "\n",
        "# Add traces, one for each slider step\n",
        "for step in np.arange(0, 2, step_width):\n",
        "    corrected_intensity = correct_intensity(df, step, window_size)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            visible=False,\n",
        "            line=dict(color=\"#00CED1\", width=2),\n",
        "            name=\"Median factor = \" + str(step),\n",
        "            x=df[\"Wavelength (nm)\"],\n",
        "            y=corrected_intensity))\n",
        "\n",
        "# Make the first trace visible\n",
        "fig.data[0].visible = True\n",
        "\n",
        "# Create and add slider\n",
        "steps = [dict(\n",
        "    method=\"update\",\n",
        "    args=[{\"visible\": [False] * len(fig.data)},\n",
        "          {\"title\": \"Median factor value: \" + str(round(i*step_width, 2))}],\n",
        ") for i in range(len(fig.data))]\n",
        "\n",
        "for i in range(len(fig.data)):\n",
        "    steps[i]['args'][0]['visible'][i] = True\n",
        "\n",
        "fig.update_layout(\n",
        "    sliders=[dict(active=0, currentvalue={\"prefix\": \"Median Factor: \"}, pad={\"t\": 50}, steps=steps)],\n",
        "    template='none', height=500, width=1500,\n",
        "    xaxis=dict(title='Wavelength (nm)', showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True),\n",
        "    yaxis=dict(title='Corrected Intensity (Counts)', showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        ")\n",
        "\n",
        "config = {'displayModeBar': True}\n",
        "fig.show(config=config)\n"
      ],
      "metadata": {
        "id": "mVTWPTRuI7fB"
      },
      "id": "mVTWPTRuI7fB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aLiW4da4Dsl"
      },
      "source": [
        "Once you have found your desired level of correction, enter the corresponding median factor into the cell below. This code block will plot your original raw data and the new baseline corrected data. Double check that all of your peaks of interested are still there! If you think you are missing important peaks, play with the median_factor parameter until you are happy."
      ],
      "id": "6aLiW4da4Dsl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ea45bae"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# COMPARING BASELINE-CORRECTED AND RAW SPECTRA\n",
        "\n",
        "####################\n",
        "median_factor = 1.3 # Change the median factor! 1.3 is the default, but you should select your desired value from the analysis above.\n",
        "####################\n",
        "\n",
        "df = new_book\n",
        "corrected_intensity = []\n",
        "median_val = statistics.median(df[\"Intensity (au)\"])\n",
        "for i in range(40, len(df[\"Intensity (au)\"])-40):\n",
        "    w = df[\"Intensity (au)\"][i]-statistics.median(df[\"Intensity (au)\"][i-40:i+40])*median_factor\n",
        "    w = w\n",
        "    if w<0:\n",
        "        w=0\n",
        "    corrected_intensity.append(w)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df[\"Wavelength (nm)\"], y=df[\"Intensity (au)\"],  name=\"Raw Data\"))\n",
        "fig.add_trace(go.Scatter(x=df[\"Wavelength (nm)\"][range(40, len(df[\"Intensity (au)\"])-40)], y=corrected_intensity,  name=\"Baseline Corrected\"))\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(template = 'none')\n",
        "fig.update_layout(xaxis=dict(title='Wavelength (nm)', showgrid=False),\n",
        "              yaxis=dict(title='Raw/Corrected Intensity (Counts)')\n",
        ")\n",
        "\n",
        "fig.update_layout(template = 'none', height = 500, width = 1500)\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "\n",
        "\n",
        "config = {'displayModeBar': True}\n",
        "fig.show(config=config)"
      ],
      "id": "3ea45bae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCIBEBMK5dYQ"
      },
      "source": [
        "Now that our data is ready to be analyzed, we need to set up our NIST searches. Unfortunately, our wavelength measurements are never perfect. We are using eight separate linear diode arrays (LDA) to detect these peaks; LDAs consist of diodes lined up in a strip, and each diode is aligned to recieve a certain band of wavelengths. Any wavelength that falls into that band is assigned the same wavelength. For example, if we record \"693.8802 nm\", that means we had a peak somewhere within 693.8802 nm ± 0.06 nm. That error associated with our wavelength measurement is a description of our spectral resolution. In the cell below, are are ploting the distances between the wavelength measurments our instrument records (wavelength [n+1] - wavelength [n]) as a function of wavelength. Notice that we are able to measure closer peaks in some regions of the spectrum than in others. Look over the graph and describe any trends you see with your lab partners. What is the worst our error can ever be, and what wavelength does it correspond to?"
      ],
      "id": "QCIBEBMK5dYQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6572b844"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# PLOTTING SPECTRAL (WAVELENGTH) RESOLUTION AS A FUNCTION OF WAVELENGTH\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "resolution_values = [df[\"Wavelength (nm)\"][i+1] - df[\"Wavelength (nm)\"][i] for i in range(len(df[\"Wavelength (nm)\"]) - 1)]\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df[\"Wavelength (nm)\"][:-1], y=resolution_values, name=\"Resolution\", line=dict(color='black')))\n",
        "\n",
        "# Define spectrometer sections and colors\n",
        "spectrometer_sections = [\n",
        "    (200, 250),\n",
        "    (250, 300),\n",
        "    (300, 330),\n",
        "    (330, 390),\n",
        "    (390, 470),\n",
        "    (470, 590),\n",
        "    (590, 690),\n",
        "    (690, 850)\n",
        "]\n",
        "\n",
        "colors = [\n",
        "    '#8B0000',\n",
        "    '#9400D3',\n",
        "    '#4B0082',\n",
        "    '#0000FF',\n",
        "    '#00FF00',\n",
        "    '#FFFF00',\n",
        "    '#FF7F00',\n",
        "    '#FF0000'\n",
        "]\n",
        "\n",
        "# Add semi-transparent rectangles for spectrometer sections\n",
        "for idx, ((start, end), color) in enumerate(zip(spectrometer_sections, colors)):\n",
        "    fig.add_shape(type='rect',\n",
        "                  xref='x', yref='y',\n",
        "                  x0=start, y0=min(resolution_values),\n",
        "                  x1=end, y1=max(resolution_values),\n",
        "                  fillcolor=color,\n",
        "                  opacity=0.25, # Increase opacity\n",
        "                  layer=\"below\",\n",
        "                  line=dict(width=0)) # Make line transparent\n",
        "\n",
        "    # Add a dummy scatter trace for the legend entry\n",
        "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', line=dict(color=color), name=f\"Spectrometer #{idx + 1}\"))\n",
        "\n",
        "fig.update_layout(\n",
        "    template='none',\n",
        "    height=500,\n",
        "    width=800,\n",
        "    xaxis=dict(title='Wavelength (nm)', showgrid=False, gridcolor='black'),\n",
        "    yaxis=dict(title='Resolution (Δ nm)', showgrid=False, gridcolor='black')\n",
        ")\n",
        "\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "config = {'displayModeBar': True}\n",
        "fig.show(config=config)\n",
        "\n",
        "print(\"Minimum wavelength recorded:\", min(df[\"Wavelength (nm)\"]))\n",
        "print(\"Maximum wavelength recorded:\", max(df[\"Wavelength (nm)\"]))\n",
        "print(\"Worst spectral resolution:\", max(resolution_values))\n"
      ],
      "id": "6572b844"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0a9r51F7jit"
      },
      "source": [
        "To keep it simple, let's use the worst resolution for all of our searches. Now, we have a spectrum ready to process and an uncertainty to use for matching peaks. Below is a function definition--it doesn't have an output, but it allows us to determine which elements are present. It uses the Astroquery process from earlier to search for peaks matching an element.\n",
        "\n",
        "We give the function the following things:\n",
        "\n",
        "**input_elements**: a list of elements in the form [\"H I\", \"Ne I\"...]; these are the elements the function will try to match.\n",
        "\n",
        "**df**: the baseline corrected data from earlier, in the form of a dataframe.\n",
        "\n",
        "**top_count**: the number of lines to try to match; for example, a top_count of 20 would pull the 20 highest intensity lines for an element and look for them.\n",
        "\n",
        "**resolution**: this is the number we determined above which gives a some wiggle room for the wavelength matches.\n",
        "\n",
        "**threshold**: the number of lines we must match to consider an element to be present.\n",
        "\n",
        "**min_wl**: the minimum wavelength for our search; our instrument measures between 200 and 850 nm, so this value stays at 200 nm.\n",
        "\n",
        "**max_wl**: the minimum wavelength for our search; our instrument measures between 200 and 850 nm, so this value stays at 850 nm.\n",
        "\n",
        "Then the function returns a list of which elements were in the sample, a list of the corresponding peaks that were matched, and a list of peaks that were not found."
      ],
      "id": "I0a9r51F7jit"
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUIRED\n",
        "# CREATING AN ELEMENT SEARCH FUNCTION\n",
        "\n",
        "from astropy import units as u\n",
        "import statistics\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def find_elements(input_elements, df, top_count=20, resolution=0.06, threshold=5, min_wl=200, max_wl=850):\n",
        "\n",
        "    # Making containers for matching wavelengths and their corresponding elements and intensities.\n",
        "    ref_wavelength_matches_lists = []\n",
        "    ref_intensity_matches_lists = []\n",
        "    ref_element_matches_lists = []\n",
        "    exp_wavelength_matches_lists = []\n",
        "    exp_intensity_matches_lists = []\n",
        "\n",
        "\n",
        "    # Iterate through each element in input_elements\n",
        "    for element in input_elements:\n",
        "\n",
        "        # Filtering the input based on intensity\n",
        "        filtered_input = df[df[\"Intensity (au)\"] > 1]\n",
        "        filtered_wavelengths = filtered_input[\"Wavelength (nm)\"].values\n",
        "\n",
        "        # Querying the NIST database for information about the element\n",
        "        table = Nist.query(minwav= min_wl * u.nm, maxwav = max_wl * u.nm, linename=element)\n",
        "\n",
        "        # Data cleaning and preparation\n",
        "        datatable_version = table.to_pandas()\n",
        "        datatable_version_clean = datatable_version.dropna(subset=[\"Rel.\"])\n",
        "        datatable_version_clean['Intensity'] = [''.join(filter(str.isdigit, str(i))) for i in datatable_version_clean[\"Rel.\"]]\n",
        "        datatable_version_clean['Intensity'].replace('', np.nan, inplace=True)\n",
        "        datatable_version_clean.dropna(subset=[\"Intensity\"], inplace=True)\n",
        "        datatable_version_clean['Intensity'] = datatable_version_clean['Intensity'].astype(int)\n",
        "        final_table = datatable_version_clean[datatable_version_clean[\"Intensity\"] > statistics.median(datatable_version_clean[\"Intensity\"])]\n",
        "        datatable_version_clean.sort_values(by=['Intensity'], ascending=False, inplace=True)\n",
        "\n",
        "\n",
        "        datatable_version_clean['Observed'] = pd.to_numeric(datatable_version_clean['Observed'], errors='coerce')\n",
        "\n",
        "        datatable_version_clean = datatable_version_clean[(datatable_version_clean['Observed'] > min_wl) & (datatable_version_clean['Observed'] < max_wl)]\n",
        "\n",
        "        # Initializing lists for results\n",
        "        ref_present = []\n",
        "        ref_int_present = []\n",
        "        exp_present = []\n",
        "        potentially_missing = []\n",
        "\n",
        "        # Pre-calculation outside the loop\n",
        "        top_observed = datatable_version_clean.head(top_count)['Observed'].tolist()\n",
        "        top_rel = datatable_version_clean.head(top_count)['Rel.'].tolist()\n",
        "\n",
        "        # Searching for lines within the resolution range\n",
        "        for line_number in range(len(top_observed)):\n",
        "            i = top_observed[line_number]\n",
        "            k = top_rel[line_number]\n",
        "\n",
        "            # Using NumPy to find wavelengths within the resolution range\n",
        "            within_range = np.abs(filtered_wavelengths - i) < resolution\n",
        "\n",
        "            if np.any(within_range):\n",
        "                real_wavelength = filtered_wavelengths[within_range][0]\n",
        "                ref_present.append(i)\n",
        "                exp_present.append(real_wavelength)\n",
        "                ref_int_present.append(k)\n",
        "            else:\n",
        "                potentially_missing.append(i)\n",
        "\n",
        "        # Storing the results if they meet or are above the threshold\n",
        "        if len(ref_present) >= threshold:\n",
        "            ref_wavelength_matches_lists.append(ref_present)\n",
        "            exp_wavelength_matches_lists.append(exp_present)\n",
        "            ref_element_matches_lists.append(len(ref_present) * [element])\n",
        "            ref_intensity_matches_lists.append(ref_int_present)\n",
        "\n",
        "            print(\"There are\", len(ref_present), \"of the top\", top_count, \"lines present for\", element)\n",
        "            print(\"The following lines are present:\", ref_present)\n",
        "            print(\"Double check if the following are present:\", potentially_missing)\n",
        "            print(\"_________________________________________________________________________________________________________________________\", '\\n')\n",
        "\n",
        "    return ref_wavelength_matches_lists, exp_wavelength_matches_lists, ref_element_matches_lists, ref_intensity_matches_lists\n",
        "\n",
        "print(\"Function loaded!\")\n"
      ],
      "metadata": {
        "id": "2pCeBjMY6o-h"
      },
      "id": "2pCeBjMY6o-h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQABd2a5ksQx"
      },
      "source": [
        "First, let's look at an example for why matching a single line is **never** enough to say a metal is present in our sample. None of the samples we assign students in 3216 lab should contain iron, but iron often pops up as an option when we look up peaks from our spectrum.\n",
        "\n",
        "A major concept for element determination is that if an element is present, most of its highest intensity lines should appear! Below, we first see if any of the top 10 iron lines are in our sample. Usually, this answer is no, none of the most intense iron lines are in our sample. That tells us our sample isn't iron.\n",
        "\n",
        "Then we search if any of our lines match any of the thousands of iron lines possible. Usually, this leads to many matches.\n",
        "\n",
        "Discuss with your partner--if the first search shows iron isn't present, why does the second search have so many matches?"
      ],
      "id": "sQABd2a5ksQx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie_7PhPZjGZC"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# ILLUSTRATING FALSE DISCOVERY\n",
        "\n",
        "# Are the top 10 lines of iron in our sample?\n",
        "df1 = pd.DataFrame()\n",
        "df1[\"Wavelength (nm)\"]=df[\"Wavelength (nm)\"][range(40, len(df[\"Intensity (au)\"])-40)]\n",
        "df1[\"Intensity (au)\"]=corrected_intensity\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "ref_wavelength_matches_lists, exp_wavelength_matches_lists, ref_element_matches_lists, ref_intensity_matches_lists = find_elements(\n",
        "    ['Fe I'],\n",
        "    df1,\n",
        "    top_count = 10,\n",
        "    resolution = 0.060437395351755185,\n",
        "    threshold = 0,\n",
        "    min_wl = 200,\n",
        "    max_wl = 850)\n",
        "if len(ref_wavelength_matches_lists)==0:\n",
        "  print(\"No lines matched Fe I when we search for the top 10 Fe I lines.\")\n",
        "else:\n",
        "  print(len(ref_wavelength_matches_lists[0]), \"line(s) matched Fe I when we compare to the top 10 Fe I lines.\")\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Do any of our lines match any iron lines?\n",
        "df1 = pd.DataFrame()\n",
        "df1[\"Wavelength (nm)\"]=df[\"Wavelength (nm)\"][range(40, len(df[\"Intensity (au)\"])-40)]\n",
        "df1[\"Intensity (au)\"]=corrected_intensity\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "ref_wavelength_matches_lists, exp_wavelength_matches_lists, ref_element_matches_lists, ref_intensity_matches_lists = find_elements(\n",
        "    ['Fe I'],\n",
        "    df1,\n",
        "    top_count = 6278,\n",
        "    resolution = 0.060437395351755185,\n",
        "    threshold = 1,\n",
        "    min_wl = 200,\n",
        "    max_wl = 850)"
      ],
      "id": "ie_7PhPZjGZC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeJ4x3D3n83v"
      },
      "source": [
        "Now that we know how top_count can affect our element matching, let's determine which lines are present in our sample. First, let's be restrictive. We can scan all elements in the NIST website and we can tentatively say the element is present if at least 3 of the top 5 lines are in our spectrum. Run the code below and discuss with your partner whether the elements matched make sense. Remember, you are shooting a metal inside of a chamber filled with a gas. Also keep in mind that some elements may be matched by chance, so be cautious if you find strange answers."
      ],
      "id": "VeJ4x3D3n83v"
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUIRED\n",
        "# ELEMENT-MATCHING WITH STRICT SETTINGS FOR ALL ELEMENTS\n",
        "\n",
        "# Create a list of elements to search for\n",
        "potential_elements = [\"H I\", \"He I\", \"Li I\", \"Be I\", \"B I\", \"C I\", \"N I\", \"O I\", \"F I\", \"Ne I\", \"Na I\", \"Mg I\", \"Al I\", \"Si I\", \"P I\", \"S I\", \"Cl I\", \"Ar I\",\"K I\", \"Ca I\", \"Sc I\", \"Ti I\", \"V I\", \"Cr I\", \"Mn I\", \"Fe I\", \"Co I\", \"Ni I\", \"Cu I\", \"Zn I\", \"Ga I\", \"Ge I\", \"As I\", \"Se I\", \"Br I\", \"Kr I\", \"Rb I\", \"Sr I\", \"Y I\", \"Nb I\", \"Mo I\", \"Tc I\", \"Ru I\", \"Rh I\", \"Pd I\", \"Ag I\", \"Cd I\", \"In I\", \"Sn I\", \"Sb I\", \"Te I\", \"I I\", \"Xe I\", \"Cs I\", \"Ba I\", \"Hf I\", \"Ta I\", \"W I\", \"Re I\", \"Os I\", \"Ir I\", \"Pt I\", \"Au I\", \"Hg I\", \"Tl I\", \"Pb I\", \"Li II\", \"Be II\", \"B II\", \"C II\", \"N II\", \"O II\", \"F II\", \"Ne II\", \"Na II\", \"Mg II\", \"Al II\", \"Si II\", \"P II\", \"S II\", \"Cl II\", \"Ar II\", \"Ca II\", \"Sc II\", \"Ti II\", \"V II\", \"Cr II\", \"Mn II\", \"Fe II\", \"Co II\", \"Ni II\", \"Cu II\", \"Zn II\", \"Ga II\", \"Ge II\", \"As II\", \"Se II\", \"Br II\", \"Kr II\", \"Rb II\", \"Sr II\", \"Y II\", \"Zr II\", \"Nb II\", \"Mo II\", \"Tc II\", \"Ru II\", \"Rh II\", \"Ag II\", \"Cd II\", \"In II\", \"Sn II\", \"Sb II\", \"Te II\", \"I II\", \"Xe II\", \"Cs II\", \"Ba II\", \"Hf II\", \"Ta II\", \"W II\", \"Re II\", \"Os II\", \"Pt II\", \"Au II\", \"Hg II\", \"Tl II\", \"Pb II\"]\n",
        "\n",
        "\n",
        "# Create a new DataFrame using a range of rows from the original DataFrame.\n",
        "# Limiting the range by excluding the first and last 40 points as the baseline correction algorithm\n",
        "# cannot be applied to these points. 'corrected_intensity' contains the signal intensities that were baseline corrected.\n",
        "df1 = pd.DataFrame({\n",
        "    \"Wavelength (nm)\": df[\"Wavelength (nm)\"][40:len(df[\"Intensity (au)\"])-40],\n",
        "    \"Intensity (au)\": corrected_intensity\n",
        "})\n",
        "\n",
        "# Suppress warnings related to chained assignment\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Call find_elements function with specific parameters:\n",
        "# top_count: Number of top lines to consider\n",
        "# resolution: Tolerance range for matching\n",
        "# threshold: Minimum number of lines to confirm an element\n",
        "# min_wl and max_wl: Wavelength range\n",
        "ref_wavelength_matches_lists, exp_wavelength_matches_lists, ref_element_matches_lists, ref_intensity_matches_lists = find_elements(\n",
        "    potential_elements,\n",
        "    df1,\n",
        "    top_count=3,\n",
        "    resolution=0.12437395351755185,\n",
        "    threshold=3,\n",
        "    min_wl=200,\n",
        "    max_wl=850\n",
        ")\n",
        "\n",
        "\n",
        "# Extracting and printing the preliminary list of elements found\n",
        "preliminary_elements = [element[0] for element in ref_element_matches_lists]\n",
        "print(\"Preliminary elements found:\", preliminary_elements)\n"
      ],
      "metadata": {
        "id": "f2eS2otc9d1m"
      },
      "id": "f2eS2otc9d1m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SGy4AKKux7T"
      },
      "source": [
        "The code block above helps narrow down the potential elements in our sample. Given the conservative approach of our initial search, we will now conduct a refined search. This next search will explore a larger set of lines, specifically the top 25, for the preliminary elements identified.\n",
        "\n",
        "When populating the list for the refined search:\n",
        "\n",
        "Ensure both neutral and ionized forms of the elements are included. For instance, if 'Cu I' was identified, add both 'Cu I' and 'Cu II' to the search.\n",
        "If any of the identified elements seem unlikely or implausible, consider omitting them from this refined search."
      ],
      "id": "-SGy4AKKux7T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9c3t5OzuSYw"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# ELEMENT-MATCHING WITH RELAXED SETTINGS FOR SPECIFIC ELEMENTS\n",
        "\n",
        "# List of specific elements for a more comprehensive search\n",
        "specific_elements = ['Ar I', 'Cu I', 'Cu II', \"Ca I\", \"Ca II\", \"O I\", \"N I\", \"Zn I\", \"Zn II\"]\n",
        "\n",
        "ref_wavelength_matches_lists, exp_wavelength_matches_lists, ref_element_matches_lists, ref_intensity_matches_lists = find_elements(\n",
        "    specific_elements,\n",
        "    df1,\n",
        "    top_count=25,\n",
        "    resolution=0.120437395351755185,\n",
        "    threshold=2\n",
        ")"
      ],
      "id": "X9c3t5OzuSYw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Zf2J4gwDLD"
      },
      "source": [
        "The output above is the primary component of our post lab assignment. It helps describe which elements are present in our sample and which emission lines support our conclusions. Unfortunately, it's not very pretty, and wouldn't export to Excel nicely. Also, the Recording Your Results section of the protocol requests these results in a very specific format.\n",
        "\n",
        "*In tabular form, compare the number, wavelength and intensities of expected spectral lines for each element present in your sample with the observed spectral lines.*\n",
        "\n",
        "We can automate the production of these tables too! We can grab the list of the lines from NIST that were found (Reference Wavelength and Reference Relative Intensity), the element those lines corresponded to (Elemental Assignment), and which peaks in our spectrum they matched (Measured Wavelength and Measured Intensity). First, let's make individual tables for each element matched."
      ],
      "id": "X4Zf2J4gwDLD"
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUIRED\n",
        "# CREATING REPORT-WORTHY TABLES BY ELEMENT\n",
        "\n",
        "# Extract raw intensities for matched wavelengths\n",
        "raw_intensities_lists = []\n",
        "for element_set in exp_wavelength_matches_lists:\n",
        "    raw_intensities = [df[\"Intensity (au)\"][df[\"Wavelength (nm)\"] == wavelength].iloc[0] for wavelength in element_set]\n",
        "    raw_intensities_lists.append(raw_intensities)\n",
        "\n",
        "# Create and display tables for each set of matched elements\n",
        "for set_number in range(len(exp_wavelength_matches_lists)):\n",
        "    element_dictionary = {\n",
        "        \"Peak Wavelength, Measured (nm)\": exp_wavelength_matches_lists[set_number],\n",
        "        \"Intensity, Measured (Counts)\": raw_intensities_lists[set_number],\n",
        "        \"Elemental Assignment\": ref_element_matches_lists[set_number],\n",
        "        \"Peak Wavelength, Reference (nm)\": ref_wavelength_matches_lists[set_number],\n",
        "        \"Relative Intensity, Reference (Counts)\": ref_intensity_matches_lists[set_number]\n",
        "    }\n",
        "    # Create a DataFrame and sort by Elemental Assignment and Intensity, then display\n",
        "    element_df = pd.DataFrame(element_dictionary)\n",
        "    display(element_df.sort_values(['Elemental Assignment', 'Intensity, Measured (Counts)'], ascending=[True, False]))\n"
      ],
      "metadata": {
        "id": "V7bFVHrCBalK"
      },
      "id": "V7bFVHrCBalK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVtIBf7G6WP9"
      },
      "source": [
        "Now, we can merge the individual tables into one large table consisiting of all of the lines found for the elements investigated. Like the eariler tables, this table could be converted into an interactive table with the wizard wand."
      ],
      "id": "kVtIBf7G6WP9"
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUIRED\n",
        "# CREATING REPORT-WORTHY TABLES WITH ALL ELEMENTS COMBINED\n",
        "\n",
        "# List to hold individual tables\n",
        "tables = []\n",
        "\n",
        "# Loop through each set of matched elements to create individual tables\n",
        "for set_number in range(len(exp_wavelength_matches_lists)):\n",
        "    element_dictionary = {\n",
        "        \"Peak Wavelength, Measured (nm)\": exp_wavelength_matches_lists[set_number],\n",
        "        \"Intensity, Measured (Counts)\": raw_intensities_lists[set_number],\n",
        "        \"Elemental Assignment\": ref_element_matches_lists[set_number],\n",
        "        \"Peak Wavelength, Reference (nm)\": ref_wavelength_matches_lists[set_number],\n",
        "        \"Relative Intensity, Reference (Counts)\": ref_intensity_matches_lists[set_number]\n",
        "    }\n",
        "    element_df = pd.DataFrame(element_dictionary)\n",
        "    tables.append(element_df)\n",
        "\n",
        "# Concatenate all the individual tables\n",
        "combined_table = pd.concat(tables)\n",
        "\n",
        "# Set option for displaying a large number of rows\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "# Sort and display the combined table\n",
        "display(combined_table.sort_values(['Elemental Assignment', 'Intensity, Measured (Counts)'], ascending=[True, False]))\n"
      ],
      "metadata": {
        "id": "NVr-SAnUDh19"
      },
      "id": "NVr-SAnUDh19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Reporting Your Results** section of the LIBS protocol requires you to include two things for each of the samples you analyzed with the LIBS setup; (1) a picture of your spectrum, and (2) a table showing at least five lines matching each element you claim to be in your sample. These last coding blocks simplify the large table from the earlier, showing only the top lines for each element. By default, it shows the five most intense lines matched for each element, but this can be changed with the top_lines_count parameter. It also saves the simplifed table as a downloadable Excel file, which has the same name as the file you uploaded with the suffix \"_elemental_analysis_summary\". It will appear in the Files tab that can be viewed by clicking the folder icon on the left-hand panel, and you can download it by clicking the three vertical dots. You can then copy and paste the table from the Excel file into your Microsoft Word document."
      ],
      "metadata": {
        "id": "9soCD0GSz27z"
      },
      "id": "9soCD0GSz27z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhX6gBqU99GL"
      },
      "outputs": [],
      "source": [
        "# REQUIRED\n",
        "# PRODUCING SIMPLIFIED TABLE FOR REPORT\n",
        "\n",
        "###################\n",
        "top_lines_count = 25 # To change the number of lines per each element, change this number.\n",
        "###################\n",
        "\n",
        "# Helper function to get top elements based on intensity\n",
        "def get_top_elements(elements, count):\n",
        "    sorted_elements = sorted(zip(elements['exp_wavelengths'], elements['raw_intensities'], elements['ref_elements'], elements['ref_wavelengths'], elements['ref_intensities']), reverse=True)\n",
        "    return [list(x) for x in zip(*sorted_elements[:count])]\n",
        "\n",
        "# Helper function to create DataFrame from lists\n",
        "def create_dataframe(exp_wavelengths, raw_intensities, ref_elements, ref_wavelengths, ref_intensities):\n",
        "    return pd.DataFrame({\n",
        "        \"Peak Wavelength, Measured (nm)\": exp_wavelengths,\n",
        "        \"Intensity, Measured (Counts)\": raw_intensities,\n",
        "        \"Elemental Assignment\": ref_elements,\n",
        "        \"Peak Wavelength, Reference (nm)\": ref_wavelengths,\n",
        "        \"Relative Intensity, Reference (Counts)\": ref_intensities\n",
        "    })\n",
        "\n",
        "# Initialize lists\n",
        "combined_elements = {\n",
        "    'exp_wavelengths': [],\n",
        "    'raw_intensities': [],\n",
        "    'ref_elements': [],\n",
        "    'ref_wavelengths': [],\n",
        "    'ref_intensities': []\n",
        "}\n",
        "\n",
        "# Loop through elements and get top lines\n",
        "for set_number in range(len(exp_wavelength_matches_lists)):\n",
        "    elements = {\n",
        "        'exp_wavelengths': exp_wavelength_matches_lists[set_number],\n",
        "        'raw_intensities': raw_intensities_lists[set_number],\n",
        "        'ref_elements': ref_element_matches_lists[set_number],\n",
        "        'ref_wavelengths': ref_wavelength_matches_lists[set_number],\n",
        "        'ref_intensities': ref_intensity_matches_lists[set_number]\n",
        "    }\n",
        "    top_elements = get_top_elements(elements, top_lines_count)\n",
        "    for i, el in enumerate(combined_elements.keys()):\n",
        "        combined_elements[el].extend(top_elements[i])\n",
        "\n",
        "# Create DataFrame and sort\n",
        "combined_table = create_dataframe(*combined_elements.values())\n",
        "combined_table = combined_table.sort_values(['Elemental Assignment', 'Intensity, Measured (Counts)'], ascending=[True, False])\n",
        "\n",
        "# Display and save as Excel\n",
        "display(combined_table)\n",
        "new_analysis_book = pd.DataFrame(combined_table)\n",
        "new_analysis_book.to_excel(final_file_name[0:len(final_file_name)-12]+'_elemental_analysis_summary.xlsx')"
      ],
      "id": "nhX6gBqU99GL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will generate a graph that labels the peaks above on our spectrum. It should match the table shown above perfectly!"
      ],
      "metadata": {
        "id": "pKojXrj5yF_j"
      },
      "id": "pKojXrj5yF_j"
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUIRED\n",
        "# PRODUCING ANNOTATED GRAPHS FOR REPORT\n",
        "\n",
        "colors = px.colors.qualitative.G10\n",
        "\n",
        "if len(ref_wavelength_matches_lists) > 10:\n",
        "  colors = colors = px.colors.qualitative.Dark24\n",
        "\n",
        "def closest_value(input_list, input_value):\n",
        "\n",
        "  difference = lambda input_list : abs(input_list - input_value)\n",
        "\n",
        "  res = min(input_list, key=difference)\n",
        "\n",
        "  return res\n",
        "\n",
        "# Making the simplfied annotated graph.\n",
        "fig = go.Figure()\n",
        "widval = 0.3\n",
        "# Add scatter trace for line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=df[\"Wavelength (nm)\"], y=df[\"Intensity (au)\"],\n",
        "    mode=\"lines\",\n",
        "    name = \"Raw data\",\n",
        "    line=dict(color='black', width=0.4)\n",
        "))\n",
        "\n",
        "for set_number in range(len(ref_wavelength_matches_lists)):\n",
        "\n",
        "    exp_wavelength_matches_list = [x for _, x in sorted(zip(raw_intensities_lists[set_number], exp_wavelength_matches_lists[set_number]), reverse=True)][0:top_lines_count]\n",
        "    raw_intensities_list = [x for _, x in sorted(zip(raw_intensities_lists[set_number], raw_intensities_lists[set_number]), reverse=True)][0:top_lines_count]\n",
        "    ref_element_matches_list = [x for _, x in sorted(zip(raw_intensities_lists[set_number], ref_element_matches_lists[set_number]), reverse=True)][0:top_lines_count]\n",
        "    ref_wavelength_matches_list = [x for _, x in sorted(zip(raw_intensities_lists[set_number], ref_wavelength_matches_lists[set_number]), reverse=True)][0:top_lines_count]\n",
        "    ref_intensity_matches_list = [x for _, x in sorted(zip(raw_intensities_lists[set_number], ref_intensity_matches_lists[set_number]), reverse=True)][0:top_lines_count]\n",
        "\n",
        "    for i in ref_wavelength_matches_list:\n",
        "            fig.add_vrect(\n",
        "            x0=i-widval, x1=i+widval,\n",
        "            fillcolor=colors[set_number], opacity=0.2,\n",
        "            layer=\"below\", line_width=0, row=2, col=1)\n",
        "\n",
        "        #find matched wavelength, #find wavelength range to search through, #find wavelength with max value\n",
        "    x_vals = []\n",
        "    y_vals= []\n",
        "    for i in ref_wavelength_matches_list:\n",
        "        val=closest_value(df[\"Wavelength (nm)\"],i)\n",
        "        index = list(df[\"Wavelength (nm)\"]).index(val)\n",
        "        candidate_list = [\n",
        "            list(df[\"Intensity (au)\"])[index-7],\n",
        "            list(df[\"Intensity (au)\"])[index-6],\n",
        "            list(df[\"Intensity (au)\"])[index-5],\n",
        "            list(df[\"Intensity (au)\"])[index-4],\n",
        "            list(df[\"Intensity (au)\"])[index-3],\n",
        "            list(df[\"Intensity (au)\"])[index-2],\n",
        "            list(df[\"Intensity (au)\"])[index-1],\n",
        "            list(df[\"Intensity (au)\"])[index],\n",
        "            list(df[\"Intensity (au)\"])[index+1],\n",
        "            list(df[\"Intensity (au)\"])[index+2],\n",
        "            list(df[\"Intensity (au)\"])[index+3],\n",
        "            list(df[\"Intensity (au)\"])[index+4],\n",
        "            list(df[\"Intensity (au)\"])[index+5],\n",
        "            list(df[\"Intensity (au)\"])[index+6],\n",
        "            list(df[\"Intensity (au)\"])[index+7]]\n",
        "        #print(\"The three options for the max are: \", candidate_list)\n",
        "        index_max_value = max(candidate_list)\n",
        "        #print(\"The max of these candidates is: \", index_max_value)\n",
        "        index_max = candidate_list.index(index_max_value)\n",
        "        #print(\"The internal index  of this value is: \", index_max)\n",
        "\n",
        "        x_val = list(df[\"Wavelength (nm)\"])[index+index_max-7]\n",
        "        y_val = list(df[\"Intensity (au)\"])[index+index_max-7]\n",
        "        x_vals.append(x_val)\n",
        "        y_vals.append(y_val)\n",
        "\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=x_vals, y=y_vals,\n",
        "        mode=\"markers+text\",\n",
        "        name=str(ref_element_matches_list[0]),\n",
        "        #text=ref_element_matches_list,\n",
        "        textfont=dict(\n",
        "        color='black'),\n",
        "        marker={\"size\":5,\n",
        "        \"color\": colors[set_number]},\n",
        "        textposition = \"bottom center\"\n",
        "    ))\n",
        "\n",
        "\n",
        "fig.update_layout(template = 'none', height = 400, width =1200)\n",
        "fig.update_layout(xaxis=dict(title='Wavelength (nm)', showgrid=False),\n",
        "              yaxis=dict(title='Intensity (Counts)', showgrid=False)\n",
        ")\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "config = {'displayModeBar': True}\n",
        "fig.show(config=config)"
      ],
      "metadata": {
        "id": "kcEwiZUuFcSK"
      },
      "id": "kcEwiZUuFcSK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Feel free to use the graph and/or table in your report! If computer programming intimidates you, you are also free to ignore this code and do your own analysis from scratch using Excel and the NIST Lines database. Note that you must include at least one annotated graph from this code to show you completed this portion of the lab.\n",
        "\n",
        "To analyze a new sample, click the Runtime tab above and select \"Disconnect and Delete Runtime\". Then, refresh the page. Now, run only the #REQUIRED cells."
      ],
      "metadata": {
        "id": "HHw6i4ORyX8J"
      },
      "id": "HHw6i4ORyX8J"
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}